import torch
import numpy as np
import os
import argparse
from tqdm import tqdm
import sys

# æŠŠå½“å‰ç›®å½•åŠ å…¥è·¯å¾„
sys.path.append(os.getcwd())

from openstl.utils import create_parser, load_config, update_config, get_dataset


def import_model_class():
    try:
        from openstl.models import MambaCast
        return MambaCast
    except ImportError:
        pass
    try:
        sys.path.append('./openstl/models')
        from mamba_model import MambaCast
        return MambaCast
    except ImportError:
        pass
    raise ImportError("Cannot find MambaCast model definition")


def generate_data():
    # --- 1. é…ç½®å‚æ•° ---
    parser = create_parser()
    args = parser.parse_args([])

    # ã€è¯·ç¡®è®¤è·¯å¾„ã€‘
    config_file = 'configs/sevir/Mamba.py'
    args.batch_size = 32
    ckpt_path = '/home/ps/data2/zp/OpenSTL-OpenSTL-Lightning/work_dirs/mamba_Anisotropic_scan_FrequencyLoss_v5/checkpoints/best.ckpt'
    save_root = './data/refiner_data'

    args.config_file = config_file
    args.dataname = 'sevir'
    args.data_root = '/home/ps/data2/zp/OpenSTL-OpenSTL-Lightning/data/sevir'
    args.batch_size = 32

    config = load_config(config_file)
    update_config(vars(args), config)

    # ================= ğŸ”§ å¼ºåŠ›ä¿®å¤: ç¡®ä¿ T ä¸æ˜¯ None =================
    # 1. å°è¯•è·å– in_shape
    if not hasattr(args, 'in_shape'):
        if hasattr(args, 'input_shape'):
            args.in_shape = args.input_shape
        else:
            args.in_shape = None  # å…ˆç½®ç©ºï¼Œåé¢å¤„ç†

    # 2. å¦‚æœè·å–åˆ°äº†ï¼Œä½†ç¬¬ä¸€ç»´æ˜¯ None (æ¯”å¦‚ (None, 1, 128, 128))ï¼Œåˆ™å¼ºåˆ¶ä¿®æ­£
    if args.in_shape is not None and args.in_shape[0] is None:
        print(f"âš ï¸ Detect None in time dimension: {args.in_shape}")
        # å¼ºåˆ¶è½¬æ¢ä¸º list ä¿®æ”¹ï¼Œå†è½¬å› tuple
        temp_shape = list(args.in_shape)
        temp_shape[0] = 13  # SEVIR å›ºå®šè¾“å…¥ 13 å¸§
        args.in_shape = tuple(temp_shape)

    # 3. å¦‚æœå®Œå…¨æ²¡æœ‰ in_shapeï¼Œæ‰‹åŠ¨æ„é€ æ ‡å‡†å½¢çŠ¶
    if args.in_shape is None:
        # SEVIR æ ‡å‡†: (13å¸§è¾“å…¥, 1é€šé“, 128é«˜, 128å®½)
        args.in_shape = (13, 1, 128, 128)

    # 4. åŒé‡ä¿é™©ï¼šå†æ¬¡æ£€æŸ¥ args.pre_seq_length
    if not hasattr(args, 'pre_seq_length') or args.pre_seq_length is None:
        args.pre_seq_length = 13

    print(f"âœ… Final Model Input Shape: {args.in_shape}")
    # ================= ğŸ”§ ä¿®å¤ç»“æŸ =================

    os.makedirs(save_root, exist_ok=True)

    # --- 2. åŠ è½½æ¨¡å‹ ---
    print("ğŸš€ Loading Stage 1 Model (Mamba)...")
    MambaCast = import_model_class()

    # ç°åœ¨ args.in_shape[0] ä¸€å®šæ˜¯ 13 (int)ï¼Œä¸ä¼šæŠ¥é”™äº†
    model = MambaCast(**vars(args)).cuda()

    checkpoint = torch.load(ckpt_path, map_location='cpu')
    state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint
    new_state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(new_state_dict, strict=False)
    model.eval()
    print("âœ… Model loaded from best.ckpt")

    # --- 3. è·å–æ•°æ®åŠ è½½å™¨ ---
    train_loader, val_loader, test_loader = get_dataset(args.dataname, vars(args))

    # æˆ‘ä»¬åªå¤„ç† train å’Œ val
    modes = ['train', 'val']
    loaders = [train_loader, val_loader]

    # --- 4. åˆ†å—ç”Ÿæˆä¸ä¿å­˜ ---
    CHUNK_SIZE = 5000

    for mode, loader in zip(modes, loaders):
        print(f"\nğŸ“¦ Processing {mode} set...")

        chunk_preds, chunk_gts, chunk_last = [], [], []
        chunk_idx = 0
        total_samples = 0

        mode_save_dir = os.path.join(save_root, mode)
        os.makedirs(mode_save_dir, exist_ok=True)

        with torch.no_grad():
            for batch_idx, (batch_x, batch_y) in enumerate(tqdm(loader)):
                batch_x = batch_x.cuda().float()

                # Mamba æ¨ç†
                pred_y = model(batch_x)

                # æå–æ•°æ® (è½¬ float16 èŠ‚çœä¸€åŠç¡¬ç›˜ç©ºé—´ï¼Œç²¾åº¦è¶³å¤Ÿ)
                last_frame = batch_x[:, -1:, :, :, :].cpu().numpy().astype(np.float16)
                pred_numpy = pred_y.cpu().numpy().astype(np.float16)
                gt_numpy = batch_y.cpu().numpy().astype(np.float16)

                chunk_preds.append(pred_numpy)
                chunk_gts.append(gt_numpy)
                chunk_last.append(last_frame)

                current_len = sum([x.shape[0] for x in chunk_preds])

                # å¦‚æœç§¯æ”’å¤Ÿäº† CHUNK_SIZEï¼Œå°±å­˜ä¸€æ¬¡
                if current_len >= CHUNK_SIZE:
                    save_chunk(mode_save_dir, mode, chunk_idx, chunk_preds, chunk_gts, chunk_last)
                    chunk_idx += 1
                    total_samples += current_len
                    # æ¸…ç©ºç¼“å­˜
                    chunk_preds, chunk_gts, chunk_last = [], [], []

        # å¾ªç¯ç»“æŸåï¼Œä¿å­˜å‰©ä¸‹çš„æ•°æ®
        if chunk_preds:
            save_chunk(mode_save_dir, mode, chunk_idx, chunk_preds, chunk_gts, chunk_last)
            total_samples += sum([x.shape[0] for x in chunk_preds])

        print(f"âœ… {mode} set finished! Total samples: {total_samples}")
        print(f"ğŸ“‚ Saved in: {mode_save_dir}")


def save_chunk(root, mode, idx, preds, gts, lasts):
    """è¾…åŠ©å‡½æ•°ï¼šä¿å­˜åˆ†å—æ•°æ®"""
    p = np.concatenate(preds, axis=0)
    g = np.concatenate(gts, axis=0)
    l = np.concatenate(lasts, axis=0)

    np.save(os.path.join(root, f'{mode}_preds_{idx:03d}.npy'), p)
    np.save(os.path.join(root, f'{mode}_gts_{idx:03d}.npy'), g)
    np.save(os.path.join(root, f'{mode}_last_{idx:03d}.npy'), l)


if __name__ == '__main__':
    generate_data()